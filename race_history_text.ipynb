{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1KHj80fkIYqMXCoiG7Y-6pcEDrxm1Qv1i",
      "authorship_tag": "ABX9TyMRRxv8hPX8JTxnpCZ+/PM+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hansk112/python_practice/blob/main/race_history_text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6N_zaID_477r"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "files = [\"/content/drive/MyDrive/race_history/complete_racing_history_0_100.csv\",\n",
        "         \"/content/drive/MyDrive/race_history/complete_racing_history_101_200.csv\",\n",
        "         \"/content/drive/MyDrive/race_history/complete_racing_history_201_300.csv\",\n",
        "         \"/content/drive/MyDrive/race_history/complete_racing_history_301_400.csv\",\n",
        "         \"/content/drive/MyDrive/race_history/complete_racing_history_401_500.csv\",\n",
        "         \"/content/drive/MyDrive/race_history/complete_racing_history_501_600.csv\",\n",
        "         \"/content/drive/MyDrive/race_history/complete_racing_history_701_800.csv\",\n",
        "         \"/content/drive/MyDrive/race_history/complete_racing_history_801_900.csv\",\n",
        "         \"/content/drive/MyDrive/race_history/complete_racing_history_901_1000.csv\",\n",
        "         \"/content/drive/MyDrive/race_history/complete_racing_history_1001_1100.csv\",\n",
        "         \"/content/drive/MyDrive/race_history/complete_racing_history_1101_1284.csv\"\n",
        "         ]\n",
        "\n",
        "df  = pd.DataFrame()\n",
        "\n",
        "\n",
        "for file in files:\n",
        "  data = pd.read_csv(file)\n",
        "  df = pd.concat([df,data],axis=0)\n",
        "\n",
        "df.to_csv('/content/drive/MyDrive/race_history/merged_race_history.csv',index=False)  \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/race_history/merged_race_history.csv\")\n",
        "print(df.describe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyLiiA925Whc",
        "outputId": "7826e552-fe61-43bf-ac03-a08a53cd53ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method NDFrame.describe of         Unnamed: 0  FIN           RUNNER        JOCKEY      SP  \\\n",
            "0                0  SCR      Gingerbread           SCR     NaN   \n",
            "1                1  SCR          Creator           SCR     NaN   \n",
            "2                0  SCR        Montezuma           SCR     NaN   \n",
            "3                1  SCR          Trieste           SCR     NaN   \n",
            "4                2  SCR        Speakeasy           SCR     NaN   \n",
            "...            ...  ...              ...           ...     ...   \n",
            "130342           8    9  Sweet Lilly (8)  Rohan Mudhoo   $9.80   \n",
            "130343           9   10    Holy Loch (3)  Lee Callaway  $64.10   \n",
            "130344          10   11     Anteater (7)  Jason Laking  $24.30   \n",
            "130345          11  SCR       Yeah Right           SCR     NaN   \n",
            "130346          12  SCR    Ideal Warrior           SCR     NaN   \n",
            "\n",
            "                          RACE COMMENTS   POS   DAYS STAKES   WGT  ...   L600  \\\n",
            "0                                   NaN   NaN    NaN    NaN   NaN  ...    NaN   \n",
            "1                                   NaN   NaN    NaN    NaN   NaN  ...    NaN   \n",
            "2                                   NaN   NaN    NaN    NaN   NaN  ...    NaN   \n",
            "3                                   NaN   NaN    NaN    NaN   NaN  ...    NaN   \n",
            "4                                   NaN   NaN    NaN    NaN   NaN  ...    NaN   \n",
            "...                                 ...   ...    ...    ...   ...  ...    ...   \n",
            "130342  Akw,8th otr to cn,never in hunt  Back   20.0     $0  56.5  ...  36.57   \n",
            "130343        5bk inr to cn,out,no dash  Back  152.0     $0  57.5  ...  36.66   \n",
            "130344           Rear group all the way  Rear   33.0     $0  59.0  ...  36.82   \n",
            "130345                        Scratched   NaN    NaN    NaN   NaN  ...    NaN   \n",
            "130346                        Scratched   NaN    NaN    NaN   NaN  ...    NaN   \n",
            "\n",
            "         RAT              DATE   M               COURSE  \\\n",
            "0        NaN   29 January 2023  M2                Taupo   \n",
            "1        NaN   29 January 2023  M2                Taupo   \n",
            "2        NaN   29 January 2023  M2                Taupo   \n",
            "3        NaN   29 January 2023  M2                Taupo   \n",
            "4        NaN   29 January 2023  M2                Taupo   \n",
            "...      ...               ...  ..                  ...   \n",
            "130342  90.0  02 December 2022  M6  Riccarton Synthetic   \n",
            "130343  89.0  02 December 2022  M6  Riccarton Synthetic   \n",
            "130344  88.0  02 December 2022  M6  Riccarton Synthetic   \n",
            "130345   NaN  02 December 2022  M6  Riccarton Synthetic   \n",
            "130346   NaN  02 December 2022  M6  Riccarton Synthetic   \n",
            "\n",
            "                                     CLUB MONTH  YEAR MEETING  MONTH_NUM  \n",
            "0                            Racing Taupo   Jan  2023       2          1  \n",
            "1                            Racing Taupo   Jan  2023       2          1  \n",
            "2                            Racing Taupo   Jan  2023       2          1  \n",
            "3                            Racing Taupo   Jan  2023       2          1  \n",
            "4                            Racing Taupo   Jan  2023       2          1  \n",
            "...                                   ...   ...   ...     ...        ...  \n",
            "130342  Canterbury Racing-Canterbury J.C.   Dec  2022       6         12  \n",
            "130343  Canterbury Racing-Canterbury J.C.   Dec  2022       6         12  \n",
            "130344  Canterbury Racing-Canterbury J.C.   Dec  2022       6         12  \n",
            "130345  Canterbury Racing-Canterbury J.C.   Dec  2022       6         12  \n",
            "130346  Canterbury Racing-Canterbury J.C.   Dec  2022       6         12  \n",
            "\n",
            "[130347 rows x 22 columns]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4 as bs\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "racing_info_list = []\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/race_history/srape_format_0_100.csv\")\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "  \n",
        "  # loop through 12 races  \n",
        "  for race_no in range(13):\n",
        "  \n",
        "    # print(row[\"YEAR\"],row[\"MONTH_NUM\"],row[\"DAY\"],row[\"MEETING\"])\n",
        "    # use url library to open url\n",
        "    website = \"https://formproratings.co.nz/form/racing/results/?dt=\" + str(row[\"YEAR\"]) +\"-\" + str(row[\"MONTH_NUM\"]) + \"-\" + str(row[\"DAY\"]) + \"&tab=\" + str(row[\"MEETING\"]) +\"&no=\" + str(race_no)\n",
        "    # print(website)\n",
        "    \n",
        "    source = urllib.request.urlopen(\"https://formproratings.co.nz/form/racing/results/?dt=\" + str(row[\"YEAR\"]) +\"-\" + str(row[\"MONTH_NUM\"]) + \"-\" + str(row[\"DAY\"]) + \"&tab=\" + str(row[\"MEETING\"]) +\"&no=\" + str(race_no)).read()\n",
        "\n",
        "    soup = bs.BeautifulSoup(source,\"lxml\")\n",
        "    \n",
        "    try:\n",
        "      race_info = soup.find(\"h4\").get_text()\n",
        "      race_info = str(race_info)\n",
        "      # print(race_info)\n",
        "\n",
        "      df_race_info = pd.DataFrame([race_info])\n",
        "\n",
        "      # print(df_race_info.head())\n",
        "      df_race_info[\"DATE\"]       = row[\"DATE\"]\n",
        "      df_race_info[\"M\"]          = row[\"M\"]\n",
        "      df_race_info[\"COURSE\"]     = row[\"COURSE\"] \n",
        "      df_race_info[\"CLUB\"]       = row[\"CLUB\"] \n",
        "      df_race_info[\"MONTH\"]      = row[\"MONTH\"]\n",
        "      df_race_info[\"YEAR\"]       = row[\"YEAR\"]\n",
        "      df_race_info[\"MEETING\"]    = row[\"MEETING\"] \n",
        "      df_race_info[\"MONTH_NUM\"]  = row[\"MONTH_NUM\"] \n",
        "\n",
        "      racing_info_list.append(df_race_info)\n",
        "    except:\n",
        "      pass      \n",
        "    \n",
        "\n",
        "df_race_info = pd.concat(racing_info_list)\n",
        "\n",
        "df_race_info.to_csv(\"/content/drive/MyDrive/race_history/racing_information_0_100.csv\")\n",
        "\n"
      ],
      "metadata": {
        "id": "_-n39oKUVSwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4 as bs\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "racing_info_list = []\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/race_history/srape_format_101_200.csv\")\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "  \n",
        "  # loop through 12 races  \n",
        "  for race_no in range(13):\n",
        "  \n",
        "    # print(row[\"YEAR\"],row[\"MONTH_NUM\"],row[\"DAY\"],row[\"MEETING\"])\n",
        "    # use url library to open url\n",
        "    website = \"https://formproratings.co.nz/form/racing/results/?dt=\" + str(row[\"YEAR\"]) +\"-\" + str(row[\"MONTH_NUM\"]) + \"-\" + str(row[\"DAY\"]) + \"&tab=\" + str(row[\"MEETING\"]) +\"&no=\" + str(race_no)\n",
        "    # print(website)\n",
        "    \n",
        "    source = urllib.request.urlopen(\"https://formproratings.co.nz/form/racing/results/?dt=\" + str(row[\"YEAR\"]) +\"-\" + str(row[\"MONTH_NUM\"]) + \"-\" + str(row[\"DAY\"]) + \"&tab=\" + str(row[\"MEETING\"]) +\"&no=\" + str(race_no)).read()\n",
        "\n",
        "    soup = bs.BeautifulSoup(source,\"lxml\")\n",
        "    \n",
        "    try:\n",
        "      race_info = soup.find(\"h4\").get_text()\n",
        "      race_info = str(race_info)\n",
        "      # print(race_info)\n",
        "\n",
        "      df_race_info = pd.DataFrame([race_info])\n",
        "\n",
        "      # print(df_race_info.head())\n",
        "      df_race_info[\"DATE\"]       = row[\"DATE\"]\n",
        "      df_race_info[\"M\"]          = row[\"M\"]\n",
        "      df_race_info[\"COURSE\"]     = row[\"COURSE\"] \n",
        "      df_race_info[\"CLUB\"]       = row[\"CLUB\"] \n",
        "      df_race_info[\"MONTH\"]      = row[\"MONTH\"]\n",
        "      df_race_info[\"YEAR\"]       = row[\"YEAR\"]\n",
        "      df_race_info[\"MEETING\"]    = row[\"MEETING\"] \n",
        "      df_race_info[\"MONTH_NUM\"]  = row[\"MONTH_NUM\"] \n",
        "\n",
        "      racing_info_list.append(df_race_info)\n",
        "    except:\n",
        "      pass      \n",
        "    \n",
        "\n",
        "df_race_info = pd.concat(racing_info_list)\n",
        "\n",
        "df_race_info.to_csv(\"/content/drive/MyDrive/race_history/racing_information_101_200.csv\")\n"
      ],
      "metadata": {
        "id": "uTPbsx-KVhZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4 as bs\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "racing_info_list = []\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/race_history/srape_format_201_300.csv\")\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "  \n",
        "  # loop through 12 races  \n",
        "  for race_no in range(13):\n",
        "  \n",
        "    # print(row[\"YEAR\"],row[\"MONTH_NUM\"],row[\"DAY\"],row[\"MEETING\"])\n",
        "    # use url library to open url\n",
        "    website = \"https://formproratings.co.nz/form/racing/results/?dt=\" + str(row[\"YEAR\"]) +\"-\" + str(row[\"MONTH_NUM\"]) + \"-\" + str(row[\"DAY\"]) + \"&tab=\" + str(row[\"MEETING\"]) +\"&no=\" + str(race_no)\n",
        "    # print(website)\n",
        "    \n",
        "    source = urllib.request.urlopen(\"https://formproratings.co.nz/form/racing/results/?dt=\" + str(row[\"YEAR\"]) +\"-\" + str(row[\"MONTH_NUM\"]) + \"-\" + str(row[\"DAY\"]) + \"&tab=\" + str(row[\"MEETING\"]) +\"&no=\" + str(race_no)).read()\n",
        "\n",
        "    soup = bs.BeautifulSoup(source,\"lxml\")\n",
        "    \n",
        "    try:\n",
        "      race_info = soup.find(\"h4\").get_text()\n",
        "      race_info = str(race_info)\n",
        "      # print(race_info)\n",
        "\n",
        "      df_race_info = pd.DataFrame([race_info])\n",
        "\n",
        "      # print(df_race_info.head())\n",
        "      df_race_info[\"DATE\"]       = row[\"DATE\"]\n",
        "      df_race_info[\"M\"]          = row[\"M\"]\n",
        "      df_race_info[\"COURSE\"]     = row[\"COURSE\"] \n",
        "      df_race_info[\"CLUB\"]       = row[\"CLUB\"] \n",
        "      df_race_info[\"MONTH\"]      = row[\"MONTH\"]\n",
        "      df_race_info[\"YEAR\"]       = row[\"YEAR\"]\n",
        "      df_race_info[\"MEETING\"]    = row[\"MEETING\"] \n",
        "      df_race_info[\"MONTH_NUM\"]  = row[\"MONTH_NUM\"] \n",
        "\n",
        "      racing_info_list.append(df_race_info)\n",
        "    except:\n",
        "      pass      \n",
        "    \n",
        "\n",
        "df_race_info = pd.concat(racing_info_list)\n",
        "\n",
        "df_race_info.to_csv(\"/content/drive/MyDrive/race_history/racing_information_201_300.csv\")\n"
      ],
      "metadata": {
        "id": "9_SPBRM3VpBW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4 as bs\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "racing_info_list = []\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/race_history/srape_format_301_400.csv\")\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "  \n",
        "  # loop through 12 races  \n",
        "  for race_no in range(13):\n",
        "  \n",
        "    # print(row[\"YEAR\"],row[\"MONTH_NUM\"],row[\"DAY\"],row[\"MEETING\"])\n",
        "    # use url library to open url\n",
        "    website = \"https://formproratings.co.nz/form/racing/results/?dt=\" + str(row[\"YEAR\"]) +\"-\" + str(row[\"MONTH_NUM\"]) + \"-\" + str(row[\"DAY\"]) + \"&tab=\" + str(row[\"MEETING\"]) +\"&no=\" + str(race_no)\n",
        "    # print(website)\n",
        "    \n",
        "    source = urllib.request.urlopen(\"https://formproratings.co.nz/form/racing/results/?dt=\" + str(row[\"YEAR\"]) +\"-\" + str(row[\"MONTH_NUM\"]) + \"-\" + str(row[\"DAY\"]) + \"&tab=\" + str(row[\"MEETING\"]) +\"&no=\" + str(race_no)).read()\n",
        "\n",
        "    soup = bs.BeautifulSoup(source,\"lxml\")\n",
        "    \n",
        "    try:\n",
        "      race_info = soup.find(\"h4\").get_text()\n",
        "      race_info = str(race_info)\n",
        "      # print(race_info)\n",
        "\n",
        "      df_race_info = pd.DataFrame([race_info])\n",
        "\n",
        "      # print(df_race_info.head())\n",
        "      df_race_info[\"DATE\"]       = row[\"DATE\"]\n",
        "      df_race_info[\"M\"]          = row[\"M\"]\n",
        "      df_race_info[\"COURSE\"]     = row[\"COURSE\"] \n",
        "      df_race_info[\"CLUB\"]       = row[\"CLUB\"] \n",
        "      df_race_info[\"MONTH\"]      = row[\"MONTH\"]\n",
        "      df_race_info[\"YEAR\"]       = row[\"YEAR\"]\n",
        "      df_race_info[\"MEETING\"]    = row[\"MEETING\"] \n",
        "      df_race_info[\"MONTH_NUM\"]  = row[\"MONTH_NUM\"] \n",
        "\n",
        "      racing_info_list.append(df_race_info)\n",
        "    except:\n",
        "      pass      \n",
        "    \n",
        "\n",
        "df_race_info = pd.concat(racing_info_list)\n",
        "\n",
        "df_race_info.to_csv(\"/content/drive/MyDrive/race_history/racing_information_301_400.csv\")\n"
      ],
      "metadata": {
        "id": "HD1ppNg4Vtls"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4 as bs\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "racing_info_list = []\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/race_history/srape_format_401_500.csv\")\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "  \n",
        "  # loop through 12 races  \n",
        "  for race_no in range(13):\n",
        "  \n",
        "    # print(row[\"YEAR\"],row[\"MONTH_NUM\"],row[\"DAY\"],row[\"MEETING\"])\n",
        "    # use url library to open url\n",
        "    website = \"https://formproratings.co.nz/form/racing/results/?dt=\" + str(row[\"YEAR\"]) +\"-\" + str(row[\"MONTH_NUM\"]) + \"-\" + str(row[\"DAY\"]) + \"&tab=\" + str(row[\"MEETING\"]) +\"&no=\" + str(race_no)\n",
        "    # print(website)\n",
        "    \n",
        "    source = urllib.request.urlopen(\"https://formproratings.co.nz/form/racing/results/?dt=\" + str(row[\"YEAR\"]) +\"-\" + str(row[\"MONTH_NUM\"]) + \"-\" + str(row[\"DAY\"]) + \"&tab=\" + str(row[\"MEETING\"]) +\"&no=\" + str(race_no)).read()\n",
        "\n",
        "    soup = bs.BeautifulSoup(source,\"lxml\")\n",
        "    \n",
        "    try:\n",
        "      race_info = soup.find(\"h4\").get_text()\n",
        "      race_info = str(race_info)\n",
        "      # print(race_info)\n",
        "\n",
        "      df_race_info = pd.DataFrame([race_info])\n",
        "\n",
        "      # print(df_race_info.head())\n",
        "      df_race_info[\"DATE\"]       = row[\"DATE\"]\n",
        "      df_race_info[\"M\"]          = row[\"M\"]\n",
        "      df_race_info[\"COURSE\"]     = row[\"COURSE\"] \n",
        "      df_race_info[\"CLUB\"]       = row[\"CLUB\"] \n",
        "      df_race_info[\"MONTH\"]      = row[\"MONTH\"]\n",
        "      df_race_info[\"YEAR\"]       = row[\"YEAR\"]\n",
        "      df_race_info[\"MEETING\"]    = row[\"MEETING\"] \n",
        "      df_race_info[\"MONTH_NUM\"]  = row[\"MONTH_NUM\"] \n",
        "\n",
        "      racing_info_list.append(df_race_info)\n",
        "    except:\n",
        "      pass      \n",
        "    \n",
        "\n",
        "df_race_info = pd.concat(racing_info_list)\n",
        "\n",
        "df_race_info.to_csv(\"/content/drive/MyDrive/race_history/racing_information_401_500.csv\")\n"
      ],
      "metadata": {
        "id": "AobYhjPpVy6l"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4 as bs\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "racing_info_list = []\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/race_history/srape_format_501_600.csv\")\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "  \n",
        "  # loop through 12 races  \n",
        "  for race_no in range(13):\n",
        "  \n",
        "    # print(row[\"YEAR\"],row[\"MONTH_NUM\"],row[\"DAY\"],row[\"MEETING\"])\n",
        "    # use url library to open url\n",
        "    website = \"https://formproratings.co.nz/form/racing/results/?dt=\" + str(row[\"YEAR\"]) +\"-\" + str(row[\"MONTH_NUM\"]) + \"-\" + str(row[\"DAY\"]) + \"&tab=\" + str(row[\"MEETING\"]) +\"&no=\" + str(race_no)\n",
        "    # print(website)\n",
        "    \n",
        "    source = urllib.request.urlopen(\"https://formproratings.co.nz/form/racing/results/?dt=\" + str(row[\"YEAR\"]) +\"-\" + str(row[\"MONTH_NUM\"]) + \"-\" + str(row[\"DAY\"]) + \"&tab=\" + str(row[\"MEETING\"]) +\"&no=\" + str(race_no)).read()\n",
        "\n",
        "    soup = bs.BeautifulSoup(source,\"lxml\")\n",
        "    \n",
        "    try:\n",
        "      race_info = soup.find(\"h4\").get_text()\n",
        "      race_info = str(race_info)\n",
        "      # print(race_info)\n",
        "\n",
        "      df_race_info = pd.DataFrame([race_info])\n",
        "\n",
        "      # print(df_race_info.head())\n",
        "      df_race_info[\"DATE\"]       = row[\"DATE\"]\n",
        "      df_race_info[\"M\"]          = row[\"M\"]\n",
        "      df_race_info[\"COURSE\"]     = row[\"COURSE\"] \n",
        "      df_race_info[\"CLUB\"]       = row[\"CLUB\"] \n",
        "      df_race_info[\"MONTH\"]      = row[\"MONTH\"]\n",
        "      df_race_info[\"YEAR\"]       = row[\"YEAR\"]\n",
        "      df_race_info[\"MEETING\"]    = row[\"MEETING\"] \n",
        "      df_race_info[\"MONTH_NUM\"]  = row[\"MONTH_NUM\"] \n",
        "\n",
        "      racing_info_list.append(df_race_info)\n",
        "    except:\n",
        "      pass      \n",
        "    \n",
        "\n",
        "df_race_info = pd.concat(racing_info_list)\n",
        "\n",
        "df_race_info.to_csv(\"/content/drive/MyDrive/race_history/racing_information_501_600.csv\")\n"
      ],
      "metadata": {
        "id": "m5XAO1hBV4i9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4 as bs\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "racing_info_list = []\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/race_history/srape_format_601_700.csv\")\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "  \n",
        "  # loop through 12 races  \n",
        "  for race_no in range(13):\n",
        "  \n",
        "    # print(row[\"YEAR\"],row[\"MONTH_NUM\"],row[\"DAY\"],row[\"MEETING\"])\n",
        "    # use url library to open url\n",
        "    website = \"https://formproratings.co.nz/form/racing/results/?dt=\" + str(row[\"YEAR\"]) +\"-\" + str(row[\"MONTH_NUM\"]) + \"-\" + str(row[\"DAY\"]) + \"&tab=\" + str(row[\"MEETING\"]) +\"&no=\" + str(race_no)\n",
        "    # print(website)\n",
        "    \n",
        "    source = urllib.request.urlopen(\"https://formproratings.co.nz/form/racing/results/?dt=\" + str(row[\"YEAR\"]) +\"-\" + str(row[\"MONTH_NUM\"]) + \"-\" + str(row[\"DAY\"]) + \"&tab=\" + str(row[\"MEETING\"]) +\"&no=\" + str(race_no)).read()\n",
        "\n",
        "    soup = bs.BeautifulSoup(source,\"lxml\")\n",
        "    \n",
        "    try:\n",
        "      race_info = soup.find(\"h4\").get_text()\n",
        "      race_info = str(race_info)\n",
        "      # print(race_info)\n",
        "\n",
        "      df_race_info = pd.DataFrame([race_info])\n",
        "\n",
        "      # print(df_race_info.head())\n",
        "      df_race_info[\"DATE\"]       = row[\"DATE\"]\n",
        "      df_race_info[\"M\"]          = row[\"M\"]\n",
        "      df_race_info[\"COURSE\"]     = row[\"COURSE\"] \n",
        "      df_race_info[\"CLUB\"]       = row[\"CLUB\"] \n",
        "      df_race_info[\"MONTH\"]      = row[\"MONTH\"]\n",
        "      df_race_info[\"YEAR\"]       = row[\"YEAR\"]\n",
        "      df_race_info[\"MEETING\"]    = row[\"MEETING\"] \n",
        "      df_race_info[\"MONTH_NUM\"]  = row[\"MONTH_NUM\"] \n",
        "\n",
        "      racing_info_list.append(df_race_info)\n",
        "    except:\n",
        "      pass      \n",
        "    \n",
        "\n",
        "df_race_info = pd.concat(racing_info_list)\n",
        "\n",
        "df_race_info.to_csv(\"/content/drive/MyDrive/race_history/racing_information_601_700.csv\")\n"
      ],
      "metadata": {
        "id": "dFBaZb87V8cF"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qh1pOF7k7kr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QPwfuHrq711L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GFk20K-F8uiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dNe-Xj998uk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YYoZ_dFL8wgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nXiSzhZb9OBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q6ApAeEy9OD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HL6tqNaK9Qfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fIMxnljM-_Yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ypV8uyLJ-_ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SFW453Ck_VVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y1zFl6QC_VX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AjHHF-Fq_06Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gX3ivE79_08B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s08OinS0_9aT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dzl3yL9F7nFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4 as bs\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "racing_info_list = []\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/race_history/srape_format_701_800.csv\")\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "  \n",
        "  # loop through 12 races  \n",
        "  for race_no in range(13):\n",
        "  \n",
        "    # print(row[\"YEAR\"],row[\"MONTH_NUM\"],row[\"DAY\"],row[\"MEETING\"])\n",
        "    # use url library to open url\n",
        "    website = \"https://formproratings.co.nz/form/racing/results/?dt=\" + str(row[\"YEAR\"]) +\"-\" + str(row[\"MONTH_NUM\"]) + \"-\" + str(row[\"DAY\"]) + \"&tab=\" + str(row[\"MEETING\"]) +\"&no=\" + str(race_no)\n",
        "    # print(website)\n",
        "    \n",
        "    source = urllib.request.urlopen(\"https://formproratings.co.nz/form/racing/results/?dt=\" + str(row[\"YEAR\"]) +\"-\" + str(row[\"MONTH_NUM\"]) + \"-\" + str(row[\"DAY\"]) + \"&tab=\" + str(row[\"MEETING\"]) +\"&no=\" + str(race_no)).read()\n",
        "\n",
        "    soup = bs.BeautifulSoup(source,\"lxml\")\n",
        "    \n",
        "    try:\n",
        "      race_info = soup.find(\"h4\").get_text()\n",
        "      race_info = str(race_info)\n",
        "      # print(race_info)\n",
        "\n",
        "      df_race_info = pd.DataFrame([race_info])\n",
        "\n",
        "      # print(df_race_info.head())\n",
        "      df_race_info[\"DATE\"]       = row[\"DATE\"]\n",
        "      df_race_info[\"M\"]          = row[\"M\"]\n",
        "      df_race_info[\"COURSE\"]     = row[\"COURSE\"] \n",
        "      df_race_info[\"CLUB\"]       = row[\"CLUB\"] \n",
        "      df_race_info[\"MONTH\"]      = row[\"MONTH\"]\n",
        "      df_race_info[\"YEAR\"]       = row[\"YEAR\"]\n",
        "      df_race_info[\"MEETING\"]    = row[\"MEETING\"] \n",
        "      df_race_info[\"MONTH_NUM\"]  = row[\"MONTH_NUM\"] \n",
        "\n",
        "      racing_info_list.append(df_race_info)\n",
        "    except:\n",
        "      pass      \n",
        "    \n",
        "\n",
        "df_race_info = pd.concat(racing_info_list)\n",
        "\n",
        "df_race_info.to_csv(\"/content/drive/MyDrive/race_history/racing_information_701_800.csv\")\n"
      ],
      "metadata": {
        "id": "V2xa3kIaWAml"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4 as bs\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "racing_info_list = []\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/race_history/srape_format_801_900.csv\")\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "  \n",
        "  # loop through 12 races  \n",
        "  for race_no in range(13):\n",
        "  \n",
        "    # print(row[\"YEAR\"],row[\"MONTH_NUM\"],row[\"DAY\"],row[\"MEETING\"])\n",
        "    # use url library to open url\n",
        "    website = \"https://formproratings.co.nz/form/racing/results/?dt=\" + str(row[\"YEAR\"]) +\"-\" + str(row[\"MONTH_NUM\"]) + \"-\" + str(row[\"DAY\"]) + \"&tab=\" + str(row[\"MEETING\"]) +\"&no=\" + str(race_no)\n",
        "    # print(website)\n",
        "    \n",
        "    source = urllib.request.urlopen(\"https://formproratings.co.nz/form/racing/results/?dt=\" + str(row[\"YEAR\"]) +\"-\" + str(row[\"MONTH_NUM\"]) + \"-\" + str(row[\"DAY\"]) + \"&tab=\" + str(row[\"MEETING\"]) +\"&no=\" + str(race_no)).read()\n",
        "\n",
        "    soup = bs.BeautifulSoup(source,\"lxml\")\n",
        "    \n",
        "    try:\n",
        "      race_info = soup.find(\"h4\").get_text()\n",
        "      race_info = str(race_info)\n",
        "      # print(race_info)\n",
        "\n",
        "      df_race_info = pd.DataFrame([race_info])\n",
        "\n",
        "      # print(df_race_info.head())\n",
        "      df_race_info[\"DATE\"]       = row[\"DATE\"]\n",
        "      df_race_info[\"M\"]          = row[\"M\"]\n",
        "      df_race_info[\"COURSE\"]     = row[\"COURSE\"] \n",
        "      df_race_info[\"CLUB\"]       = row[\"CLUB\"] \n",
        "      df_race_info[\"MONTH\"]      = row[\"MONTH\"]\n",
        "      df_race_info[\"YEAR\"]       = row[\"YEAR\"]\n",
        "      df_race_info[\"MEETING\"]    = row[\"MEETING\"] \n",
        "      df_race_info[\"MONTH_NUM\"]  = row[\"MONTH_NUM\"] \n",
        "\n",
        "      racing_info_list.append(df_race_info)\n",
        "    except:\n",
        "      pass      \n",
        "    \n",
        "\n",
        "df_race_info = pd.concat(racing_info_list)\n",
        "\n",
        "df_race_info.to_csv(\"/content/drive/MyDrive/race_history/racing_information_801_900.csv\")\n"
      ],
      "metadata": {
        "id": "zpkgU_yqWFDM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TZdF4YI2gznf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OQ04bt8VqaGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4 as bs\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "racing_info_list = []\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/race_history/srape_format_1101_1284.csv\")\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "  \n",
        "  # loop through 12 races  \n",
        "  for race_no in range(13):\n",
        "  \n",
        "    # print(row[\"YEAR\"],row[\"MONTH_NUM\"],row[\"DAY\"],row[\"MEETING\"])\n",
        "    # use url library to open url\n",
        "    website = \"https://formproratings.co.nz/form/racing/results/?dt=\" + str(row[\"YEAR\"]) +\"-\" + str(row[\"MONTH_NUM\"]) + \"-\" + str(row[\"DAY\"]) + \"&tab=\" + str(row[\"MEETING\"]) +\"&no=\" + str(race_no)\n",
        "    # print(website)\n",
        "    \n",
        "    source = urllib.request.urlopen(\"https://formproratings.co.nz/form/racing/results/?dt=\" + str(row[\"YEAR\"]) +\"-\" + str(row[\"MONTH_NUM\"]) + \"-\" + str(row[\"DAY\"]) + \"&tab=\" + str(row[\"MEETING\"]) +\"&no=\" + str(race_no)).read()\n",
        "\n",
        "    soup = bs.BeautifulSoup(source,\"lxml\")\n",
        "    \n",
        "    try:\n",
        "      race_info = soup.find(\"h4\").get_text()\n",
        "      race_info = str(race_info)\n",
        "      # print(race_info)\n",
        "\n",
        "      df_race_info = pd.DataFrame([race_info])\n",
        "\n",
        "      # print(df_race_info.head())\n",
        "      df_race_info[\"DATE\"]       = row[\"DATE\"]\n",
        "      df_race_info[\"M\"]          = row[\"M\"]\n",
        "      df_race_info[\"COURSE\"]     = row[\"COURSE\"] \n",
        "      df_race_info[\"CLUB\"]       = row[\"CLUB\"] \n",
        "      df_race_info[\"MONTH\"]      = row[\"MONTH\"]\n",
        "      df_race_info[\"YEAR\"]       = row[\"YEAR\"]\n",
        "      df_race_info[\"MEETING\"]    = row[\"MEETING\"] \n",
        "      df_race_info[\"MONTH_NUM\"]  = row[\"MONTH_NUM\"] \n",
        "\n",
        "      racing_info_list.append(df_race_info)\n",
        "    except:\n",
        "      pass      \n",
        "    \n",
        "\n",
        "df_race_info = pd.concat(racing_info_list)\n",
        "\n",
        "df_race_info.to_csv(\"/content/drive/MyDrive/race_history/racing_information_1101_1284.csv\")\n"
      ],
      "metadata": {
        "id": "dmEuajCWWUR3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ieEORVIIkVu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tdvOlTRe65pR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xV5OD0xt68Z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LLdsl3ARB3h-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RE6MAs7IB3kE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-fje-85IB_vy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f542u8TxCCgi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}